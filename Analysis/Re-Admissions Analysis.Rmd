---
title: "Re-Admissions Analysis"
author: "Kathleen Sheehan & Abhishek Kanaparthi"
date: "November 8, 2017"
output:
  word_document: default
  html_document: default
---

The following document elucidates about the in-depth analysis of the Re-Admissions Data and tries to find out the most important factors that are contributing for the Re-admission and also for finding patterns in the data, that will help reduce the number of re-admits.

```{r, message=FALSE, warning=FALSE}
library(readr)
readmitsV1 <- read_csv("R:/People's Projects/Kathleen Sheehan Projects/Data/readmitsV1.csv")
```

Now as the data has been imported, we can go ahead and start working on the dataset with the basic filtering part of it.

```{r}
optional = c(1,2,4,6,7,8,9,10,18,19,41)
group1 = c(20,21,22,23,24,25,26,27,28,29,30,31,32,33)
group2 = c(34,35,36,37,38,39)

rad1= readmitsV1[optional] # Building the dataset with the most important columns only
rad2= readmitsV1[group1]
rad3= readmitsV1[group2]

target = readmitsV1[3] # Storing the Target Variable

# Making a new Data Frame with only the desired varirables
rad.raw = cbind(target,rad1,rad2,rad3)
```

As the data has been designed now, the next step is to check the structure of the data.

```{r}
str(rad.raw)
summary(rad.raw)
```

The next step is to convert the ones with the categorical data into factors.

```{r}
library(tidyverse)
library(magrittr)
library(dplyr)
library(plyr)

cols=c(1:6,8:10,13:26,28:32)
rad.raw %<>% mutate_at(cols, funs(factor(.)))
```

As we have changed the type of the variables now, we can go ahead and check the datatype now again.

```{r}
str(rad.raw)
summary(rad.raw)
```

The next step is to work on using one group of variables alone to do the analysis and then the next.

We have to fix upon the most important variables before we jump into the logistic regression on the same.

```{r}
library(devtools)
#install_github("riv","tomasgreif")
#install_github("woe","tomasgreif")
library(woe)
library(riv)

iv.mult(rad.raw,"READMIT",summary = TRUE, verbose = TRUE)
```


You can also find the relative significance of the variables from predictor screening in JMP.

![Analysis for just the Rad.raw](R:/People's Projects/Kathleen Sheehan Projects/R- Programming/Readmissions/figures/Rad Raw.JPG)

The further analysis can be done with the usage of the important variables or can also be done with the help of some of the groups of variables to help understand the importance of the variables in a step by step manner, rather than in a whole manner.

The following predictors are choosen just to check a model, which can be developed with the variables with the least number of missing values, just to develop the simplest prototype of the model in case we finalise the most important predictors after the screening analysis.


```{r}
predictors = c(1, 2:4, 6:11)
logit1 = glm(data = rad.raw[predictors], rad.raw$READMIT~., family = binomial(link = "logit"))
summary(logit1)
```

```{r, message=FALSE, warning=FALSE}
predictedProb = predict(logit1,type = "response")
library(InformationValue)
optCutOff <- optimalCutoff(rad.raw$READMIT, predictedProb)[1] 
optCutOff
```

The next sep is to check the accuracy of the model.

```{r, message=FALSE, warning=FALSE}
target = ifelse(rad.raw$READMIT == "YES", 1, 0)
print(paste("Mis-Class error is :",misClassError(target, predictedProb, threshold = optCutOff)))
#plotROC(target, predictions)
sensitivity(target, predictedProb, threshold = optCutOff)
specificity(target, predictedProb, threshold = optCutOff)
```

```{r, message=FALSE, warning=FALSE}
targetRef = rad.raw$READMIT[!is.na(rad.raw$FIN_CLASS)]
targetRefNum = ifelse(targetRef == "YES", 1, 0)
targetPredicted = ifelse(predictedProb > optCutOff, 1, 0)

library(caret)
library(e1071)
confusionMatrix(data = logit1$y, reference = targetRefNum, positive = "1")
```

